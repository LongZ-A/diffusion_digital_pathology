{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "from scipy.stats import sem,tmean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mcc(confusion_matrix):\n",
    "    num_classes = len(confusion_matrix)\n",
    "    mcc_values = np.zeros(num_classes)\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        tp = confusion_matrix[i, i]\n",
    "        fp = np.sum(confusion_matrix[:, i]) - tp\n",
    "        fn = np.sum(confusion_matrix[i, :]) - tp\n",
    "        tn = np.sum(confusion_matrix) - tp - fp - fn\n",
    "        \n",
    "        mcc_values[i] = (tp * tn - fp * fn) / np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "    \n",
    "    mcc = np.mean(mcc_values)\n",
    "    \n",
    "    return mcc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the responses and the correct answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dir = os.getcwd()\n",
    "Q_dir = os.path.join(curr_dir,'Questionnaires')\n",
    "Q_dir = os.path.join(Q_dir,'Original')\n",
    "all_files  = sorted(os.listdir(Q_dir))\n",
    "\n",
    "responses = []\n",
    "for file in all_files:\n",
    "    if 'P' in file:\n",
    "        dir = os.path.join(Q_dir,file)\n",
    "        responses.append(pd.read_csv(dir))\n",
    "correct = pd.read_csv('Questionnaires/Original/Correct_answers.csv',header=None)\n",
    "class_labels = sorted(pd.unique(correct[4]).tolist())\n",
    "class_to_idx = {}\n",
    "num_classes = len(class_labels)\n",
    "for i,clss in enumerate(class_labels):\n",
    "    class_to_idx[clss] = i\n",
    "real_fake = {'fake':0,'real':1}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and calculate the confusion matrices for each task and pathologist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix_task1_real_all = {}\n",
    "cf_matrix_task1_fake_all = {}\n",
    "cf_matrix_task2_all = {}\n",
    "mistake_real_all = {}\n",
    "mistake_fake_all = {}\n",
    "\n",
    "\n",
    "for p,response in enumerate(responses):\n",
    "    all_replies = response.iloc[0].to_numpy()[2:]\n",
    "    cf_matrix_task1_real = np.zeros(shape=(num_classes,num_classes))\n",
    "    cf_matrix_task1_fake = np.zeros(shape=(num_classes,num_classes))\n",
    "    cf_matrix_task2 = np.zeros((2,2))\n",
    "    mistake_real = {}\n",
    "    mistake_fake = {}\n",
    "\n",
    "    for clss in class_labels:\n",
    "        mistake_real[clss] = 0\n",
    "        mistake_fake[clss] = 0\n",
    "    for idx,reply in enumerate(all_replies):\n",
    "        if correct.iloc[idx][1] == 'first':\n",
    "            idx_row = class_to_idx[correct.loc[idx][4]]\n",
    "            idx_column = class_to_idx[reply]\n",
    "            if correct.iloc[idx][3] == 'real':\n",
    "                cf_matrix_task1_real[idx_row,idx_column] += 1\n",
    "            else:\n",
    "                cf_matrix_task1_fake[idx_row,idx_column] += 1\n",
    "        elif correct.loc[idx][1] == 'second':\n",
    "            idx_row =  real_fake[correct.loc[idx][3]]\n",
    "            idx_column = real_fake[reply]\n",
    "            cf_matrix_task2[idx_row,idx_column] += 1\n",
    "            if idx_row != idx_column:\n",
    "                if correct.loc[idx][3] == 'real':\n",
    "                    mistake_real[correct.loc[idx][4]] += 1\n",
    "                elif correct.loc[idx][3] == 'fake':\n",
    "                    mistake_fake[correct.loc[idx][4]] += 1\n",
    "    dic_name = 'Pathologist' + str(p+1)\n",
    "    cf_matrix_task1_fake_all[dic_name] = cf_matrix_task1_fake\n",
    "    cf_matrix_task1_real_all[dic_name] = cf_matrix_task1_real\n",
    "    cf_matrix_task2_all[dic_name] = cf_matrix_task2\n",
    "    mistake_fake_all[dic_name] = mistake_fake\n",
    "    mistake_real_all[dic_name] = mistake_real\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results of the first task on the real data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pathologists = len(cf_matrix_task1_real_all.keys())\n",
    "num_per_tissue = 10\n",
    "width_ratios = []\n",
    "color = 'Blues'\n",
    "for i in range(num_pathologists+1):\n",
    "    width_ratios.append(1)\n",
    "figsz = ((num_pathologists+1)*3.54,3.54)\n",
    "clss_labels = class_labels\n",
    "font_properties = {'fontname': 'sans-serif', 'fontsize': 12}\n",
    "sup_ttl = 'Tissue detection task on real tiles'\n",
    "sup_font_properties = {'fontname': 'sans-serif', 'fontsize': 14}\n",
    "fig,axes = plt.subplots(1,num_pathologists+1, \n",
    "            gridspec_kw={'width_ratios':width_ratios},figsize = figsz,dpi = 600);\n",
    "fig.suptitle(sup_ttl,**sup_font_properties)\n",
    "conf_matrix_total = np.zeros((num_classes,num_classes))\n",
    "for num,key in enumerate(cf_matrix_task1_real_all):\n",
    "    ttl = key\n",
    "    conf_matrix = cf_matrix_task1_real_all[key]\n",
    "    conf_matrix_total += conf_matrix\n",
    "    df_conf_matrix = pd.DataFrame(conf_matrix,index= [i for i in clss_labels],columns= [i for i in clss_labels])\n",
    "    if num == 0:\n",
    "        g = sn.heatmap(df_conf_matrix,annot=True,cmap= color,vmin=0,vmax=num_per_tissue,square=True,cbar=False,ax=axes[num]);\n",
    "        g.set_ylabel('actual',**font_properties);\n",
    "    else:\n",
    "        g = sn.heatmap(df_conf_matrix,fmt=\".0f\",cmap = color,annot=True,vmin=0,vmax=num_per_tissue,cbar=False,square=True,ax=axes[num]);\n",
    "        g.set_yticks([])\n",
    "    g.set_xlabel('predicted',**font_properties);\n",
    "    g.set_title(ttl,**font_properties);\n",
    "df_conf_matrix_total = pd.DataFrame(conf_matrix_total,index= [i for i in clss_labels],columns= [i for i in clss_labels])\n",
    "g = sn.heatmap(df_conf_matrix_total,fmt=\".0f\",cmap = color,annot=True,square=True,vmin=0,vmax=num_per_tissue*num_pathologists,cbar=False,ax=axes[num+1],cbar_ax=axes[-1]);\n",
    "g.set_yticks([])\n",
    "g.set_xlabel('predicted',**font_properties);\n",
    "g.set_title('Combined',**font_properties);\n",
    "\n",
    "for ax in axes:\n",
    "    ax.tick_params(axis='both', labelsize=10,width = 1)\n",
    "plt.tight_layout()\n",
    "\n",
    "for num,key in enumerate(cf_matrix_task1_real_all):\n",
    "    cf_matrix = cf_matrix_task1_real_all[key]\n",
    "    mcc = calculate_mcc(cf_matrix)\n",
    "    acc = np.diagonal(cf_matrix).sum() / np.sum(cf_matrix)\n",
    "    print(key,': ','MCC: ',mcc,' Accuracy: ',acc*100,'%')\n",
    "mcc = calculate_mcc(conf_matrix_total)\n",
    "acc = np.diagonal(conf_matrix_total).sum() / np.sum(conf_matrix_total)\n",
    "print('All pathologists combined: MCC:',mcc,' Accuracy: ',acc*100,'%')\n",
    "plt.savefig(os.path.join(os.getcwd(),'task1_real_pathologists.png'),dpi=600)\n",
    "plt.savefig(os.path.join(os.getcwd(),'task1_real_pathologists.svg'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results of the first task on the fake data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pathologists = len(cf_matrix_task1_fake_all.keys())\n",
    "num_per_tissue = 10\n",
    "width_ratios = []\n",
    "color = 'Blues'\n",
    "for i in range(num_pathologists+1):\n",
    "    width_ratios.append(1)\n",
    "figsz = ((num_pathologists+1)*3.54,3.54)\n",
    "clss_labels = class_labels\n",
    "font_properties = {'fontname': 'sans-serif', 'fontsize': 12}\n",
    "sup_ttl = 'Tissue detection task on fake tiles'\n",
    "sup_font_properties = {'fontname': 'sans-serif', 'fontsize': 14}\n",
    "fig,axes = plt.subplots(1,num_pathologists+1, \n",
    "            gridspec_kw={'width_ratios':width_ratios},figsize = figsz,dpi = 600);\n",
    "fig.suptitle(sup_ttl,**sup_font_properties)\n",
    "conf_matrix_total = np.zeros((num_classes,num_classes))\n",
    "for num,key in enumerate(cf_matrix_task1_fake_all):\n",
    "    ttl = key\n",
    "    conf_matrix = cf_matrix_task1_fake_all[key]\n",
    "    conf_matrix_total += conf_matrix\n",
    "    df_conf_matrix = pd.DataFrame(conf_matrix,index= [i for i in clss_labels],columns= [i for i in clss_labels])\n",
    "    if num == 0:\n",
    "        g = sn.heatmap(df_conf_matrix,cmap = color,annot=True,vmin=0,fmt=\".0f\",vmax=num_per_tissue,square=True,cbar=False,ax=axes[num]);\n",
    "        g.set_ylabel('actual',**font_properties);\n",
    "    else:\n",
    "        g = sn.heatmap(df_conf_matrix,cmap=color,annot=True,fmt=\".0f\",vmin=0,vmax=num_per_tissue,cbar=False,square=True,ax=axes[num]);\n",
    "        g.set_yticks([])\n",
    "    g.set_xlabel('predicted',**font_properties);\n",
    "    g.set_title(ttl,**font_properties);\n",
    "df_conf_matrix_total = pd.DataFrame(conf_matrix_total,index= [i for i in clss_labels],columns= [i for i in clss_labels])\n",
    "g = sn.heatmap(df_conf_matrix_total,annot=True,cmap = color,fmt=\".0f\",square=True,vmin=0,vmax=num_per_tissue*num_pathologists,cbar=False,ax=axes[num+1],cbar_ax=axes[-1]);\n",
    "g.set_yticks([])\n",
    "g.set_xlabel('predicted',**font_properties);\n",
    "g.set_title('Combined',**font_properties);\n",
    "\n",
    "for ax in axes:\n",
    "    ax.tick_params(axis='both', labelsize=10,width = 1);\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "for num,key in enumerate(cf_matrix_task1_fake_all):\n",
    "    cf_matrix = cf_matrix_task1_fake_all[key]\n",
    "    mcc = calculate_mcc(cf_matrix)\n",
    "    acc = np.diagonal(cf_matrix).sum() / np.sum(cf_matrix)\n",
    "    print(key,': ','MCC: ',mcc,' Accuracy: ',acc*100,'%')\n",
    "mcc = calculate_mcc(conf_matrix_total)\n",
    "acc = np.diagonal(conf_matrix_total).sum() / np.sum(conf_matrix_total)\n",
    "print('All pathologists combined: MCC:',mcc,' Accuracy: ',acc*100,'%')\n",
    "\n",
    "plt.savefig(os.path.join(os.getcwd(),'task1_fake_pathologists.png'),dpi=600)\n",
    "plt.savefig(os.path.join(os.getcwd(),'task1_fake_pathologists.svg'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results of the second task (real vs fake) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pathologists = len(cf_matrix_task1_fake_all.keys())\n",
    "num_per_type = 50\n",
    "width_ratios = []\n",
    "color = 'Blues'\n",
    "font_properties = {'fontname': 'sans-serif', 'fontsize': 12}\n",
    "figsz = ((num_pathologists+1)*3.54,3.54)\n",
    "clss_labels = ['generated','real']\n",
    "sup_ttl = 'fake vs real'\n",
    "sup_font_properties = {'fontname': 'sans-serif', 'fontsize': 14}\n",
    "\n",
    "for i in range(num_pathologists+1):\n",
    "    width_ratios.append(1)\n",
    "fig,axes = plt.subplots(1,num_pathologists+1, \n",
    "            gridspec_kw={'width_ratios':width_ratios},figsize = figsz,dpi = 600);\n",
    "fig.suptitle(sup_ttl,**sup_font_properties)\n",
    "conf_matrix_total= np.zeros((len(clss_labels),len(clss_labels)))\n",
    "for num,key in enumerate(cf_matrix_task2_all):\n",
    "    ttl = key\n",
    "    conf_matrix = cf_matrix_task2_all[key]\n",
    "    conf_matrix_total += conf_matrix\n",
    "    df_conf_matrix = pd.DataFrame(conf_matrix,index= [i for i in clss_labels],columns= [i for i in clss_labels])\n",
    "    if num == 0:\n",
    "        g = sn.heatmap(df_conf_matrix,square=True,cmap = color,fmt=\".0f\",annot=True,vmin=0,vmax=num_per_type,cbar=False,ax=axes[num]);\n",
    "        g.set_ylabel('actual',**font_properties);\n",
    "    else:\n",
    "        g = sn.heatmap(df_conf_matrix,square=True,cmap = color,fmt=\".0f\",annot=True,vmin=0,vmax=num_per_type,cbar=False,ax=axes[num]);\n",
    "        g.set_yticks([])\n",
    "    g.set_xlabel('predicted',**font_properties);\n",
    "    g.set_title(ttl,**font_properties);\n",
    "\n",
    "df_conf_matrix_total = pd.DataFrame(conf_matrix_total,index= [i for i in clss_labels],columns= [i for i in clss_labels])\n",
    "g = sn.heatmap(df_conf_matrix_total,annot=True, cmap= color,fmt=\".0f\",square=True,vmin=0,vmax=num_per_type*num_pathologists,cbar=False,ax=axes[num+1],cbar_ax=axes[-1]);\n",
    "g.set_yticks([])\n",
    "g.set_xlabel('predicted',**font_properties);\n",
    "g.set_title('overall',**font_properties);\"\"\n",
    "\n",
    "for ax in axes:\n",
    "    ax.tick_params(axis='both', labelsize=10,width = 1);\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "for num,key in enumerate(cf_matrix_task2_all.keys()):\n",
    "    cf_matrix = cf_matrix_task2_all[key]\n",
    "    mcc = calculate_mcc(cf_matrix)\n",
    "    acc = np.diagonal(cf_matrix).sum() / np.sum(cf_matrix)\n",
    "    print(key,': ','MCC: ',mcc,' Accuracy: ',acc*100,'%')\n",
    "mcc = calculate_mcc(conf_matrix_total)\n",
    "acc = np.diagonal(conf_matrix_total).sum() / np.sum(conf_matrix_total)\n",
    "print('All pathologists combined: MCC:',mcc,' Accuracy: ',acc*100,'%')\n",
    "\n",
    "plt.savefig(os.path.join(os.getcwd(),'task2_pathologists.png'),dpi=600)\n",
    "plt.savefig(os.path.join(os.getcwd(),'task2_pathologists.svg'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the number of errors per tissue for the second task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistake_real_avg = {}\n",
    "mistake_real_se = {}\n",
    "mistake_fake_avg = {}\n",
    "mistake_fake_se = {}\n",
    "\n",
    "\n",
    "\n",
    "for tissue in class_labels:\n",
    "    tmp_real = []\n",
    "    tmp_fake = []\n",
    "    for key in mistake_real_all:\n",
    "        tmp_real.append(mistake_real_all[key][tissue])\n",
    "        tmp_fake.append(mistake_fake_all[key][tissue])\n",
    "    mistake_real_avg[tissue] = tmean(tmp_real)\n",
    "    mistake_real_se[tissue] = sem(tmp_real)\n",
    "    mistake_fake_avg[tissue] = tmean(tmp_fake)\n",
    "    mistake_fake_se[tissue] = sem(tmp_fake)\n",
    "\n",
    "figsz = ((num_pathologists+1)*3.54,3.54)\n",
    "fig = plt.figure(figsize=figsz,dpi=600)\n",
    "font_properties = {'fontname': 'sans-serif', 'fontsize': 12}\n",
    "\n",
    "data = mistake_real_avg\n",
    "names = list(data.keys())\n",
    "values = list(data.values())\n",
    "err = list(mistake_real_se.values())\n",
    "ttl = 'real tiles detected as fake'\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax1.bar(range(len(data)), values, tick_label=names,linewidth=1)\n",
    "ax1.errorbar(range(len(data)), values,yerr=[np.zeros(len(err)),err],fmt='o', capsize=4, color='red',linewidth=0.75)\n",
    "ax1.set_xlabel(\"tissues\",**font_properties)\n",
    "ax1.set_ylabel(\"# of mistakes\",**font_properties)\n",
    "ax1.set_title(ttl,**font_properties);\n",
    "ax1.tick_params(axis='both', labelsize=10,width = 1)\n",
    "\n",
    "\n",
    "data = mistake_fake_avg\n",
    "err = list(mistake_fake_se.values())\n",
    "names = list(data.keys())\n",
    "values = list(data.values())\n",
    "ttl = 'fake tiles detected as real'\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.bar(range(len(data)), values, tick_label=names,linewidth=1)\n",
    "ax2.errorbar(range(len(data)), values,yerr=[np.zeros(len(err)),err,],fmt='o', capsize=4, color='red',linewidth=0.75)\n",
    "ax2.set_xlabel(\"tissues\",**font_properties)\n",
    "ax2.set_title(ttl,**font_properties);\n",
    "ax2.set_yticklabels([])\n",
    "ax2.tick_params(axis='both', labelsize=10,width = 1)\n",
    "\n",
    "max_y = max(ax1.get_ylim()[1],ax2.get_ylim()[1])\n",
    "ax1.set_ylim(0,max_y)\n",
    "ax1.set_yticks(np.arange(0,int(max_y+2),2))\n",
    "ax2.set_ylim(0,max_y)\n",
    "ax2.set_yticks(np.arange(0,int(max_y+2),2))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(os.getcwd(),'error_tissues.png'),dpi=600)\n",
    "plt.savefig(os.path.join(os.getcwd(),'error_tissues.svg'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The followup questionaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dir = os.getcwd()\n",
    "Q_dir = os.path.join(curr_dir,'Questionnaires')\n",
    "Q_dir = os.path.join(Q_dir,'Followup')\n",
    "file  = sorted(os.listdir(Q_dir))\n",
    "dir = os.path.join(Q_dir,file[0])\n",
    "answers = pd.read_csv(dir);\n",
    "answers.iloc[0], answers.iloc[1], answers.iloc[2]  =  answers.iloc[2].copy(), answers.iloc[0].copy(), answers.iloc[1]\n",
    "num_pathologists = answers.shape[0] - 1\n",
    "num_question = answers.shape[1] - 1\n",
    "image_features = np.array(np.concatenate((answers.values[:,1:4],answers.values[:,-1].reshape(-1, 1)),axis = 1),dtype=np.float64);\n",
    "biological_features = np.array(answers.values[:,4:-1],dtype=np.float64);\n",
    "\n",
    "names = []\n",
    "for num in range(num_pathologists+1):\n",
    "    names.append('Pathologist' + str(num+1))\n",
    "names.append('Combined')\n",
    "\n",
    "values1 = np.mean(image_features,axis = 1)\n",
    "se1 = np.std(image_features,axis = 1) / np.sqrt(image_features.shape[1])\n",
    "\n",
    "values2 = np.mean(biological_features,axis = 1)\n",
    "se2 = np.std(biological_features,axis = 1)/ np.sqrt(biological_features.shape[1])\n",
    "\n",
    "values1 = np.append(values1,np.mean(values1))\n",
    "values2 = np.append(values2,np.mean(values2))\n",
    "se1 = np.append(se1,np.std(values1)/ np.sqrt(num_pathologists))\n",
    "se2 = np.append(se2,np.std(values2)/ np.sqrt(num_pathologists))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "figsz = ((num_pathologists+1)*3.54,3.54);\n",
    "fig = plt.figure(figsize=figsz,dpi=600)\n",
    "font_properties = {'fontname': 'sans-serif', 'fontsize': 12}\n",
    "\n",
    "\n",
    "bar_width = 0.35\n",
    "x1 = np.arange(len(names))\n",
    "x2 = x1 + bar_width\n",
    "\n",
    "plt.bar(x1, values1,linewidth=1,width= bar_width,label= 'Visual attributes',color = 'tab:cyan')\n",
    "plt.errorbar(x1, values1,yerr=[np.zeros(len(se1)),se1],fmt='o', capsize=4, color='red',linewidth=0.75)\n",
    "ax = plt.gca()\n",
    "ax.set_ylabel(\"average score\",**font_properties)\n",
    "ax.tick_params(axis='both', labelsize=10,width = 1)\n",
    "\n",
    "\n",
    "\n",
    "plt.bar(x2, values2,linewidth=1,width= bar_width,label= 'Biological attributes',color = 'tab:gray')\n",
    "plt.errorbar(x2, values2,yerr=[np.zeros(len(se2)),se2],fmt='o', capsize=4, color='red',linewidth=0.75)\n",
    "\n",
    "plt.xticks((x1 + x2)/ 2, names)\n",
    "plt.legend();\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(os.getcwd(),'Q2.png'),dpi=600)\n",
    "plt.savefig(os.path.join(os.getcwd(),'Q2.svg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(values1)\n",
    "print(se1)\n",
    "print(values2)\n",
    "print(se2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
