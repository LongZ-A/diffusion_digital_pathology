{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,Subset\n",
    "import Models   \n",
    "from torchvision.models import resnet50,ResNet50_Weights\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import os \n",
    "import PIL\n",
    "from scipy.linalg import sqrtm\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from prdc import compute_prdc\n",
    "import random\n",
    "import umap \n",
    "from plotnine import ggplot,aes,geom_point,scale_color_manual\n",
    "from plotnine.labels import xlab,ylab\n",
    "import pandas as pd\n",
    "from scipy.stats import sem,tmean\n",
    "from PIL import ImageEnhance\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define The dataset and Dataloaders from the subset of the real and Fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "data_dir = os.path.abspath(os.path.join(current_directory, '..', 'real_vs_fake'))\n",
    "dataset = ImageFolder(root=data_dir,transform=transforms.ToTensor())\n",
    "dataloader = DataLoader(dataset=dataset,num_workers=8,shuffle=False,batch_size=16)\n",
    "labels = np.array(dataset.targets)\n",
    "num_classes = len(set(labels))\n",
    "idx_change = np.where(labels[:-1] != labels[1:])[0]\n",
    "idx_fake = np.where(labels == dataset.class_to_idx['fake'])[0]\n",
    "idx_real = np.where(labels == dataset.class_to_idx['real'])[0]\n",
    "dataset_real = Subset(dataset,idx_real)\n",
    "dataset_fake = Subset(dataset,idx_fake)\n",
    "transform_fake = transforms.Compose([\n",
    "            transforms.Lambda(lambda img: ImageEnhance.Sharpness(img).enhance(3)),\n",
    "            transforms.ToTensor(), \n",
    "            ])\n",
    "dataset_fake.transforms = transform_fake\n",
    "dataset_fake.transform = transform_fake\n",
    "dataloader_real = DataLoader(dataset=dataset_real,num_workers=8,shuffle=False,batch_size=16)\n",
    "dataloader_fake = DataLoader(dataset=dataset_fake,num_workers=8,shuffle=False,batch_size=16)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate The manifold similarity measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_all = {'precision': [], 'recall': [], 'density': [], 'coverage': []}\n",
    "\n",
    "for i in range(5):\n",
    "    #model = resnet50(weights= \"IMAGENET1K_V2\") for the case where u want to use the pretrained model\n",
    "    model = resnet50(weights= None)\n",
    "    linear_size = list(model.children())[-1].in_features\n",
    "    model.fc  = nn.Linear(linear_size, 100)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    embeddings_real = []\n",
    "    embeddings_random = []\n",
    "    for images,_ in tqdm(dataloader_real,desc= 'real_data'):\n",
    "        with torch.no_grad():\n",
    "            images_random = torch.rand(images.shape)\n",
    "            images_random = images_random.to(device)\n",
    "            images = images.to(device)\n",
    "            features = model(images)\n",
    "            features_random = model(images_random)\n",
    "        embeddings_real.append(features.cpu())\n",
    "        embeddings_random.append(features_random.cpu())\n",
    "    embeddings_real =  torch.cat(embeddings_real,dim=0).numpy()\n",
    "    embeddings_random = torch.cat(embeddings_random,dim=0).numpy()\n",
    "\n",
    "    embeddings_fake = []\n",
    "    for images,_ in tqdm(dataloader_fake,desc= 'fake_data'):\n",
    "        with torch.no_grad():\n",
    "            images = images.to(device)\n",
    "            features = model(images)\n",
    "        embeddings_fake.append(features.cpu())\n",
    "    embeddings_fake =  torch.cat(embeddings_fake,dim=0).numpy()\n",
    "\n",
    "    metrics = compute_prdc(real_features=embeddings_real,\n",
    "                        fake_features=embeddings_fake,\n",
    "                        nearest_k=10)\n",
    "    for key in metrics:\n",
    "        metrics_all[key].append(metrics[key])\n",
    "print(metrics_all)\n",
    "for key in metrics_all:\n",
    "    avg_value = tmean(metrics_all[key])\n",
    "    se = sem(metrics_all[key])\n",
    "    print('Average ' + key +f': {avg_value}' + '+/- ' + f'{se}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing an example manifold in 2D space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.concatenate((embeddings_fake,embeddings_real,embeddings_random),axis=0)\n",
    "shp = np.shape(embeddings_random)[0]\n",
    "labels_all = np.concatenate((labels,2*np.ones(shp)),axis=0)\n",
    "                            \n",
    "reducer = umap.UMAP()\n",
    "umap_embeddings = reducer.fit_transform(embeddings)\n",
    "df = pd.DataFrame(umap_embeddings,columns=[\"x\",\"y\"])\n",
    "pd_labels = pd.DataFrame(labels_all,columns=[\"class\"])\n",
    "mapping = [\"fake\",\"real\",\"random\"]\n",
    "\n",
    "pal = [\"#FF0000\",\n",
    "        \"#0000FF\",\n",
    "        \"#00FF00\"\n",
    "        ]\n",
    "    \n",
    "color_key = {str(d): c for d, c in enumerate(pal)}\n",
    "\n",
    "df[\"id\"] = labels_all\n",
    "\n",
    "g = ggplot(df,aes(x=\"x\",y=\"y\",color=\"factor(id)\")) +geom_point(alpha=0.5,size=1.6) + scale_color_manual(name = \"Tissue - Origin\",values = pal,labels=mapping)+xlab(\"UMAP1\")+ylab(\"UMAP2\") \n",
    "g.save(filename = './random_embedding_enh3.png', height=15, width=15, units = 'in', dpi=500) \n",
    "np.save('embedding.npy',embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the FID score between all the real data and fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from PIL import ImageEnhance\n",
    "\n",
    "gen_data_dir = os.path.abspath(os.path.join(current_directory, '..', 'Generated-data','synthetic_tiles_512TO256_GTEX'))\n",
    "real_data_dir = os.path.abspath(os.path.join(current_directory, '..', 'Train'))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform= transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.ToTensor(), \n",
    "            ])\n",
    "\n",
    "transform_fake = transforms.Compose([\n",
    "            transforms.Lambda(lambda img: ImageEnhance.Sharpness(img).enhance(3)),\n",
    "            transforms.ToTensor(), \n",
    "            ])\n",
    "\n",
    "dataset_real = ImageFolder(root=real_data_dir,transform=transform)\n",
    "dataloader_real = DataLoader(dataset=dataset_real,num_workers=8,shuffle=False,batch_size=8)\n",
    "\n",
    "dataset_gen = ImageFolder(root=gen_data_dir,transform=transform_fake)\n",
    "dataloader_gen = DataLoader(dataset=dataset_gen,num_workers=8,shuffle=False,batch_size=8)\n",
    "\n",
    "fid_v3_score = FrechetInceptionDistance(feature=2048,normalize=True).to(device)\n",
    "for images,_ in tqdm(dataloader_real,desc= 'real_data'):\n",
    "    fid_v3_score.update(images.to(device), real=True)\n",
    "\n",
    "for images,_ in tqdm(dataloader_gen,desc= 'fake_data'):\n",
    "    fid_v3_score.update(images.to(device), real=False)\n",
    "\n",
    "print(f\"FID score with inception3 network: {fid_v3_score.compute()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class based FID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "gen_data_dir = os.path.abspath(os.path.join(current_directory, '..', 'Generated-data','synthetic_tiles_512TO256_GTEX'))\n",
    "real_data_dir = os.path.abspath(os.path.join(current_directory, '..', 'Train'))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform= transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.ToTensor(), \n",
    "            ])\n",
    "\n",
    "transform_fake = transforms.Compose([\n",
    "            transforms.Lambda(lambda img: ImageEnhance.Sharpness(img).enhance(3)),\n",
    "            transforms.ToTensor(), \n",
    "            ])\n",
    "\n",
    "dataset_real = ImageFolder(root=real_data_dir,transform=transform)\n",
    "dataset_gen = ImageFolder(root=gen_data_dir,transform=transform_fake)\n",
    "\n",
    "tissues = os.listdir(real_data_dir)\n",
    "fid_class = {}\n",
    "for tissue in tissues:\n",
    "    tissue_index_real = dataset_real.class_to_idx[tissue]\n",
    "    tissue_index_gen = dataset_gen.class_to_idx[tissue]\n",
    "    idx_real_tissue = [idx for idx in range(len(dataset_real)) if dataset_real.targets[idx] == tissue_index_real]\n",
    "    idx_gen_tissue = [idx for idx in range(len(dataset_gen)) if dataset_gen.targets[idx] == tissue_index_gen]\n",
    "    dataset_real_tissue = Subset(dataset_real, idx_real_tissue)\n",
    "    dataset_gen_tissue = Subset(dataset_gen, idx_gen_tissue)\n",
    "\n",
    "    dataloader_real = DataLoader(dataset=dataset_real_tissue,num_workers=8,shuffle=False,batch_size=8)\n",
    "    dataloader_gen = DataLoader(dataset=dataset_gen_tissue,num_workers=8,shuffle=False,batch_size=8)\n",
    "    fid_v3_score = FrechetInceptionDistance(feature=2048,normalize=True).to(device)\n",
    "    for images,_ in tqdm(dataloader_real,desc= 'real_data' + '_' + tissue):\n",
    "        fid_v3_score.update(images.to(device), real=True)\n",
    "\n",
    "    for images,_ in tqdm(dataloader_gen,desc= 'fake_data' + '_' + tissue):\n",
    "        fid_v3_score.update(images.to(device), real=False)\n",
    "    fid_class[tissue] = fid_v3_score.compute()\n",
    "\n",
    "for key in fid_class:\n",
    "    print(f\"FID score with inception3 network for {key} : {fid_class[key]}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the inception score with all the generated data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageEnhance\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "\n",
    "gen_data_dir = os.path.abspath(os.path.join(current_directory, '..', 'Generated-data','synthetic_tiles_512TO256_GTEX'))\n",
    "transform= transforms.Compose([\n",
    "            transforms.Lambda(lambda img: ImageEnhance.Sharpness(img).enhance(3)),\n",
    "            transforms.ToTensor(), \n",
    "            ])\n",
    "\n",
    "dataset_gen_2 = ImageFolder(root=gen_data_dir,transform=transform)\n",
    "dataloader_gen_2 = DataLoader(dataset=dataset_gen_2,num_workers=8,shuffle=False,batch_size=8)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "inception = InceptionScore(normalize=True,splits=5).to(device)\n",
    "\n",
    "for images,_ in tqdm(dataloader_gen_2,desc= 'fake_data'):\n",
    "    inception.update(images.to(device))\n",
    "inception_v3 = inception.compute()\n",
    "print(f\"inception score with inception3 network: {inception_v3}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the inception score with the real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_dir = os.path.abspath(os.path.join(current_directory, '..', 'Train'))\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "transform= transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.ToTensor(), \n",
    "            ])\n",
    "dataset_real = ImageFolder(root=real_data_dir,transform=transform)\n",
    "dataloader_real = DataLoader(dataset=dataset_real,num_workers=8,shuffle=False,batch_size=8)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "inception = InceptionScore(normalize=True,splits=5).to(device)\n",
    "\n",
    "for images,_ in tqdm(dataloader_real,desc= 'Real_data'):\n",
    "    inception.update(images.to(device))\n",
    "inception_v3 = inception.compute()\n",
    "print(f\"inception score with inception3 network: {inception_v3}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e659ab2d2cb6427426232f03cd622886f44bd4c681a428540cb93a3b509fd9d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
